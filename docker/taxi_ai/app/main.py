import logging
from fastapi import FastAPI
from pydantic import BaseModel
import spacy
from transformers import AutoTokenizer, AutoModelForTokenClassification

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("TaxiAi")

app = FastAPI()

# ====== –ó–∞–≥—Ä—É–∑–∫–∞ spaCy ======
try:
    nlp = spacy.load("ru_core_news_sm")
    logger.info("‚úÖ spaCy model loaded successfully")
except Exception as e:
    logger.error("‚ùå Failed to load spaCy model: %s", str(e))
    nlp = None  # —á—Ç–æ–±—ã —Å–µ—Ä–≤–µ—Ä –≤—Å—ë —Ä–∞–≤–Ω–æ –ø–æ–¥–Ω—è–ª—Å—è


# ====== –ó–∞–≥—Ä—É–∑–∫–∞ HuggingFace –º–æ–¥–µ–ª–∏ ======
HF_MODEL_PATH = "/app/model/distilbert-base-multilingual-cased"

try:
    tokenizer = AutoTokenizer.from_pretrained(HF_MODEL_PATH)
    model = AutoModelForTokenClassification.from_pretrained(HF_MODEL_PATH)
    logger.info("‚úÖ HuggingFace model loaded successfully from %s", HF_MODEL_PATH)
except Exception as e:
    logger.error("‚ùå Failed to load HuggingFace model: %s", str(e))
    tokenizer = None
    model = None


class TextRequest(BaseModel):
    text: str


@app.post("/parse")
async def process_text(request: TextRequest):
    logger.info("üì© Received request with text: %s", request.text)

    response = {"text": request.text, "entities_spacy": [], "entities_hf": []}

    # spaCy –æ–±—Ä–∞–±–æ—Ç–∫–∞
    if nlp:
        try:
            doc = nlp(request.text)
            response["entities_spacy"] = [{"text": ent.text, "label": ent.label_} for ent in doc.ents]
            logger.info("spaCy entities: %s", response["entities_spacy"])
        except Exception as e:
            logger.error("Error in spaCy processing: %s", str(e))

    # Hugging Face –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–ø–æ–∫–∞ —Ç–æ–ª—å–∫–æ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∞)
    if tokenizer and model:
        try:
            inputs = tokenizer(request.text, return_tensors="pt")
            outputs = model(**inputs)
            logger.info("HF model inference successful")
            # –î–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –ø–æ–∫–∞ –Ω–µ –¥–µ–∫–æ–¥–∏—Ä—É–µ–º –º–µ—Ç–∫–∏
            response["entities_hf"] = outputs.logits.shape  # debug info
        except Exception as e:
            logger.error("Error in HuggingFace processing: %s", str(e))

    return response
